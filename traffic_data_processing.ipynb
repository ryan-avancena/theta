{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1b6c42ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4b2b5b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation_matrices(los_angeles):\n",
    "    la_numeric_cols = los_angeles.select_dtypes(include=[np.number]).columns\n",
    "\n",
    "    # correlation matrix \n",
    "    corr_matrix = los_angeles[la_numeric_cols].corr()\n",
    "    plt.figure(figsize=(12, 12))\n",
    "    sns.heatmap(corr_matrix, annot=True, fmt=\".2f\", cmap=\"coolwarm\", linewidths=0.5)\n",
    "    plt.title(\"Correlation Matrix - Los Angeles\")\n",
    "    plt.show()\n",
    "\n",
    "    # predictive values matrix \n",
    "    highly_correlated = ['AM_WAY_PHV','PM_WAY_PHV','AM_K_FACTOR_AMT','AM_D_FACTOR_AMT','AM_KD_FACTOR','PM_K_FACTOR_AMT','PM_D_FACTOR_AMT','PM_KD_FACTOR']\n",
    "    corr_matrix = los_angeles[highly_correlated].corr()\n",
    "    plt.figure(figsize=(12,12))\n",
    "    sns.heatmap(corr_matrix, annot=True, fmt=\".2f\", cmap=\"coolwarm\", linewidths=0.5)\n",
    "    plt.title(\"Correlation Matrix - Los Angeles\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fe824075",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scatter_plots(los_angeles):\n",
    "    # scatterplots\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.scatterplot(data=los_angeles, x='AM_HOUR', y='AM_WAY_PHV', alpha=0.5, edgecolor=None)\n",
    "    plt.xlabel(\"Morning Hour (AM_HOUR)\")\n",
    "    plt.ylabel(\"Volume of Cars\")\n",
    "    plt.title(\"Traffic Volume by Morning Hour in Los Angeles\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    # scatterplot with trend-line\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.regplot(data=los_angeles, x='AM_HOUR', y='AM_WAY_PHV', scatter_kws={'alpha': 0.5}, line_kws={'color': 'red'})\n",
    "    plt.xlabel(\"Morning Hour (AM_HOUR)\")\n",
    "    plt.ylabel(\"AM Peak Hour Volume (AM_WAY_PHV)\")\n",
    "    plt.title(\"Traffic Volume by Morning Hour in Los Angeles (with Trendline)\")\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a4b27153",
   "metadata": {},
   "outputs": [],
   "source": [
    "YEARS = [2016,2017,2018,2019,2020,2021,2022]\n",
    "\n",
    "def create_peak_hours():\n",
    "    all_peak_hours = []\n",
    "    for year in YEARS:\n",
    "        file_path = f'./data/peak-hours/{year}-peak-hours.xlsx'\n",
    "        try:\n",
    "            df = pd.read_excel(file_path, sheet_name=f'{year} Peak Hour Report')\n",
    "            df['YEAR'] = year  # Add year column for reference\n",
    "            # print(df.shape)\n",
    "            all_peak_hours.append(df)\n",
    "        except FileNotFoundError:\n",
    "            print(f\"File not found for year {year}, skipping...\")\n",
    "\n",
    "    # Concatenate all years into a single DataFrame\n",
    "    peak_hours_df = pd.concat(all_peak_hours, ignore_index=True)\n",
    "\n",
    "    day_mapping = {\n",
    "        'MON': 0, 'TUE': 1, 'WED': 2, \n",
    "        'THU': 3, 'FRI': 4, 'SAT': 5, 'SUN': 6\n",
    "    }\n",
    "\n",
    "    month_mapping = {\n",
    "        'JAN': 0, 'FEB': 1, 'MAR': 2, \n",
    "        'APR': 3, 'MAY': 4, 'JUN': 5, 'JUL': 6,\n",
    "        'AUG': 7,'SEP': 8,'OCT': 9,'NOV': 10,'DEC': 11\n",
    "    }\n",
    "\n",
    "    peak_hours_df['AM_DAY'] = peak_hours_df['AM_DAY'].replace(day_mapping)   \n",
    "    peak_hours_df['AM_MONTH'] = peak_hours_df['AM_MONTH'].replace(month_mapping)\n",
    "    # peak_hours_df.rename()\n",
    "\n",
    "    return peak_hours_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5a8b25ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File not found for year 2017, skipping...\n",
      "File not found for year 2018, skipping...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y0/tql4kxn91m51l1_d96hty_z40000gn/T/ipykernel_99486/4205824315.py:29: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  peak_hours_df['AM_DAY'] = peak_hours_df['AM_DAY'].replace(day_mapping)\n",
      "/var/folders/y0/tql4kxn91m51l1_d96hty_z40000gn/T/ipykernel_99486/4205824315.py:30: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  peak_hours_df['AM_MONTH'] = peak_hours_df['AM_MONTH'].replace(month_mapping)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['DI', 'RTE', 'CO', 'PM', 'LEG', 'YR', 'AM_DIR', 'AM_WAY_PHV',\n",
       "       'AM_K_FACTOR_AMT', 'AM_D_FACTOR_AMT', 'AM_KD_FACTOR', 'AM_HOUR',\n",
       "       'AM_DAY', 'AM_MONTH', 'PM_DIR', 'PM_WAY_PHV', 'PM_K_FACTOR_AMT',\n",
       "       'PM_D_FACTOR_AMT', 'PM_KD_FACTOR', 'PM_HOUR', 'PM_DAY', 'PM_MONTH',\n",
       "       'YEAR'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peak_hours = create_peak_hours()\n",
    "peak_hours.drop(columns=['RTE_SFX','PM_SFX','PM_PFX','PRE','CS'],inplace=True)\n",
    "peak_hours[['AM_DAY','PM_DAY','AM_HOUR','PM_HOUR','AM_MONTH','PM_MONTH','YEAR']]\n",
    "peak_hours['AM_MONTH'].unique()\n",
    "peak_hours.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ad0ed777",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" STATIC \"\"\"\n",
    "\n",
    "COUNTIES = ['LA','ORA','SD','SB']\n",
    "\n",
    "AM_TIME_BASED_FEATURES = ['AM_HOUR', 'AM_DAY', 'AM_MONTH','YEAR','PM']\n",
    "PM_TIME_BASED_FEATURES = ['PM_HOUR', 'PM_DAY', 'PM_MONTH','YEAR','PM']\n",
    "\n",
    "DIRECTIONS = ['N','E','S','W']\n",
    "\n",
    "# MON - 0 , SUN - 6\n",
    "DAYS = [0,1,2,3,4,5,6]\n",
    "\n",
    "# JAN - 0 , DEC - 11\n",
    "MONTHS = [0,1,2,3,4,5,6,7,8,9,10,11]\n",
    "YEARS = [2016,2017,2018,2019,2020,2021,2022]\n",
    "\n",
    "morning_results = []\n",
    "afternoon_results = []\n",
    "\n",
    "AM_TIME_BASED_FEATURES = ['AM_HOUR', 'AM_DAY', 'AM_MONTH','YEAR','PM']\n",
    "\n",
    "# MORNING TIME\n",
    "for year in YEARS:\n",
    "    df_year = peak_hours[peak_hours['YEAR'] == year]\n",
    "\n",
    "    for county in COUNTIES: \n",
    "        df_county = df_year[df_year['CO'] == county]  # Filter by county\n",
    "        \n",
    "        for direction in DIRECTIONS:\n",
    "            df_dir = df_county[df_county['AM_DIR'] == direction]  # Filter by direction\n",
    "            \n",
    "            for month in MONTHS:\n",
    "                df_month = df_dir[df_dir['AM_MONTH'] == month]\n",
    "\n",
    "                for day in DAYS:\n",
    "                    df_day = df_month[df_month['AM_DAY'] == day]  # Filter by day\n",
    "                    \n",
    "                    if df_day.shape[0] == 0:\n",
    "                        continue  # Skip empty results\n",
    "                    \n",
    "                    for index, row in df_day.iterrows():\n",
    "                        morning_results.append({\n",
    "                            'Year': year, \n",
    "                            'Month': month, \n",
    "                            'County': county, \n",
    "                            'Direction': direction, \n",
    "                            'Hour': row['AM_HOUR'],\n",
    "                            'Day': row['AM_DAY'], \n",
    "                            'PHV': row['AM_WAY_PHV']\n",
    "                        })\n",
    "\n",
    "\n",
    "# Convert results into a DataFrame for EDA\n",
    "morning_eda_df = pd.DataFrame(morning_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7a2d2dff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Year', 'Month', 'County', 'Direction', 'Hour', 'Day', 'PHV'], dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "morning_eda_df\n",
    "morning_eda_df.columns\n",
    "\n",
    "# AM_DIRECTION_FEATURES = ['AM_DIR','AM_WAY_PHV','AM_K_FACTOR_AMT','AM_D_FACTOR_AMT','AM_KD_FACTOR']\n",
    "# PM_DIRECTION_FEATURES = ['PM_DIR','PM_WAY_PHV','PM_K_FACTOR_AMT','PM_D_FACTOR_AMT','PM_KD_FACTOR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "db52bf3b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot assemble the datetimes: time data \"20160200\" doesn't match format \"%Y%m%d\", at position 0. You might want to try:\n    - passing `format` if your strings have a consistent format;\n    - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n    - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/Downloads/coding stuff/SPRING2025/theta_ryan/venv/lib/python3.11/site-packages/pandas/core/tools/datetimes.py:1214\u001b[0m, in \u001b[0;36m_assemble_from_unit_mappings\u001b[0;34m(arg, errors, utc)\u001b[0m\n\u001b[1;32m   1213\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1214\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[43mto_datetime\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mY\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mm\u001b[39;49m\u001b[38;5;132;43;01m%d\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mutc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mutc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1215\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/Downloads/coding stuff/SPRING2025/theta_ryan/venv/lib/python3.11/site-packages/pandas/core/tools/datetimes.py:1063\u001b[0m, in \u001b[0;36mto_datetime\u001b[0;34m(arg, errors, dayfirst, yearfirst, utc, format, exact, unit, infer_datetime_format, origin, cache)\u001b[0m\n\u001b[1;32m   1062\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arg, ABCSeries):\n\u001b[0;32m-> 1063\u001b[0m     cache_array \u001b[38;5;241m=\u001b[39m \u001b[43m_maybe_cache\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert_listlike\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1064\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m cache_array\u001b[38;5;241m.\u001b[39mempty:\n",
      "File \u001b[0;32m~/Downloads/coding stuff/SPRING2025/theta_ryan/venv/lib/python3.11/site-packages/pandas/core/tools/datetimes.py:247\u001b[0m, in \u001b[0;36m_maybe_cache\u001b[0;34m(arg, format, cache, convert_listlike)\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(unique_dates) \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(arg):\n\u001b[0;32m--> 247\u001b[0m     cache_dates \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_listlike\u001b[49m\u001b[43m(\u001b[49m\u001b[43munique_dates\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    248\u001b[0m     \u001b[38;5;66;03m# GH#45319\u001b[39;00m\n",
      "File \u001b[0;32m~/Downloads/coding stuff/SPRING2025/theta_ryan/venv/lib/python3.11/site-packages/pandas/core/tools/datetimes.py:433\u001b[0m, in \u001b[0;36m_convert_listlike_datetimes\u001b[0;34m(arg, format, name, utc, unit, errors, dayfirst, yearfirst, exact)\u001b[0m\n\u001b[1;32m    432\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmixed\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 433\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_array_strptime_with_fallback\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mutc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexact\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    435\u001b[0m result, tz_parsed \u001b[38;5;241m=\u001b[39m objects_to_datetime64(\n\u001b[1;32m    436\u001b[0m     arg,\n\u001b[1;32m    437\u001b[0m     dayfirst\u001b[38;5;241m=\u001b[39mdayfirst,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    441\u001b[0m     allow_object\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    442\u001b[0m )\n",
      "File \u001b[0;32m~/Downloads/coding stuff/SPRING2025/theta_ryan/venv/lib/python3.11/site-packages/pandas/core/tools/datetimes.py:467\u001b[0m, in \u001b[0;36m_array_strptime_with_fallback\u001b[0;34m(arg, name, utc, fmt, exact, errors)\u001b[0m\n\u001b[1;32m    464\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    465\u001b[0m \u001b[38;5;124;03mCall array_strptime, with fallback behavior depending on 'errors'.\u001b[39;00m\n\u001b[1;32m    466\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 467\u001b[0m result, tz_out \u001b[38;5;241m=\u001b[39m \u001b[43marray_strptime\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfmt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexact\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexact\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mutc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mutc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    468\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tz_out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32mstrptime.pyx:501\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.strptime.array_strptime\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mstrptime.pyx:451\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.strptime.array_strptime\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mstrptime.pyx:583\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.strptime._parse_with_format\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: time data \"20160200\" doesn't match format \"%Y%m%d\", at position 0. You might want to try:\n    - passing `format` if your strings have a consistent format;\n    - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n    - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m df \u001b[38;5;241m=\u001b[39m morning_eda_df\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Create a datetime object (defaults hour to 0 if missing, but we have Hour!)\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDateTime\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_datetime\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43myear\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mYear\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmonth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMonth\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mday\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDay\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhour\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mHour\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Time-based features\u001b[39;00m\n\u001b[1;32m      8\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWeekday\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDateTime\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39mweekday  \u001b[38;5;66;03m# Monday=0, Sunday=6\u001b[39;00m\n",
      "File \u001b[0;32m~/Downloads/coding stuff/SPRING2025/theta_ryan/venv/lib/python3.11/site-packages/pandas/core/tools/datetimes.py:1070\u001b[0m, in \u001b[0;36mto_datetime\u001b[0;34m(arg, errors, dayfirst, yearfirst, utc, format, exact, unit, infer_datetime_format, origin, cache)\u001b[0m\n\u001b[1;32m   1068\u001b[0m         result \u001b[38;5;241m=\u001b[39m arg\u001b[38;5;241m.\u001b[39m_constructor(values, index\u001b[38;5;241m=\u001b[39marg\u001b[38;5;241m.\u001b[39mindex, name\u001b[38;5;241m=\u001b[39marg\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m   1069\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arg, (ABCDataFrame, abc\u001b[38;5;241m.\u001b[39mMutableMapping)):\n\u001b[0;32m-> 1070\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_assemble_from_unit_mappings\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mutc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1071\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arg, Index):\n\u001b[1;32m   1072\u001b[0m     cache_array \u001b[38;5;241m=\u001b[39m _maybe_cache(arg, \u001b[38;5;28mformat\u001b[39m, cache, convert_listlike)\n",
      "File \u001b[0;32m~/Downloads/coding stuff/SPRING2025/theta_ryan/venv/lib/python3.11/site-packages/pandas/core/tools/datetimes.py:1216\u001b[0m, in \u001b[0;36m_assemble_from_unit_mappings\u001b[0;34m(arg, errors, utc)\u001b[0m\n\u001b[1;32m   1214\u001b[0m     values \u001b[38;5;241m=\u001b[39m to_datetime(values, \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, errors\u001b[38;5;241m=\u001b[39merrors, utc\u001b[38;5;241m=\u001b[39mutc)\n\u001b[1;32m   1215\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m-> 1216\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot assemble the datetimes: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00merr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   1218\u001b[0m units: \u001b[38;5;28mlist\u001b[39m[UnitChoices] \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mh\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mm\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ms\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mms\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mus\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mns\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1219\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m u \u001b[38;5;129;01min\u001b[39;00m units:\n",
      "\u001b[0;31mValueError\u001b[0m: cannot assemble the datetimes: time data \"20160200\" doesn't match format \"%Y%m%d\", at position 0. You might want to try:\n    - passing `format` if your strings have a consistent format;\n    - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n    - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this."
     ]
    }
   ],
   "source": [
    "# Make sure your DataFrame exists\n",
    "df = morning_eda_df.copy()\n",
    "\n",
    "# Create a datetime object (defaults hour to 0 if missing, but we have Hour!)\n",
    "df['DateTime'] = pd.to_datetime(dict(year=df.Year, month=df.Month+1, day=df.Day, hour=df.Hour))\n",
    "\n",
    "# Time-based features\n",
    "df['Weekday'] = df['DateTime'].dt.weekday  # Monday=0, Sunday=6\n",
    "df['IsWeekend'] = df['Weekday'] >= 5\n",
    "df['Quarter'] = df['DateTime'].dt.quarter\n",
    "df['IsRushHour'] = df['Hour'].between(7, 9)  # Customize this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f796f1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVR  # Regression SVM\n",
    "\n",
    "# Copy data\n",
    "df = morning_eda_df.copy()\n",
    "\n",
    "# Encode categorical features\n",
    "le_county = LabelEncoder()\n",
    "le_direction = LabelEncoder()\n",
    "df['County'] = le_county.fit_transform(df['County'])\n",
    "df['Direction'] = le_direction.fit_transform(df['Direction'])\n",
    "\n",
    "# Features and target\n",
    "X = df.drop('PHV', axis=1)\n",
    "y = df['PHV']\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aba89ef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 13092137.23839206\n",
      "R^2 Score: 0.00259744068021428\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "svm = SVR(kernel='rbf')  # you can also try 'linear', 'poly'\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = svm.predict(X_test)\n",
    "print(\"MSE:\", mean_squared_error(y_test, y_pred))\n",
    "print(\"R^2 Score:\", r2_score(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
